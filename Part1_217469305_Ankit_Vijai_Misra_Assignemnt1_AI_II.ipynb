{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "hmpMttwcsyMJ",
    "outputId": "73eb34e4-400b-49f5-a9f8-aebb6733f796"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VEmcVD7syMg"
   },
   "outputs": [],
   "source": [
    "# Function to pre-process the input data\n",
    "def preprocess(data):\n",
    "  # Missing Value Treatment: the OHLC (open high low close) data is a continuous timeseries hence filled with fill forwards values.\n",
    "  data['open'].fillna(method='ffill', inplace=True)\n",
    "  data['high'].fillna(method='ffill', inplace=True)\n",
    "  data['low'].fillna(method='ffill', inplace=True)\n",
    "  data['close'].fillna(method='ffill', inplace=True)\n",
    "    # volume is a single event and hence NA's are replaced with zeroes\n",
    "  data['volume'].fillna(value=0, inplace=True)\n",
    "\n",
    "  # changing to datetime and index assignment to date variable\n",
    "  data['date'] = pd.to_datetime(data['date'])\n",
    "  data = data.groupby([pd.Grouper(key='date', freq='H')]).first().reset_index()\n",
    "  data = data.set_index('date')\n",
    "  data = data[['close']]\n",
    "  return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8C-sjQHBsyM4"
   },
   "outputs": [],
   "source": [
    "# Function to split data into train and test based on a splitting date\n",
    "def split(data, split_date):\n",
    "  split_date = split_date\n",
    "  data_train = data.loc[data.index <= split_date].copy()\n",
    "  data_test = data.loc[data.index > split_date].copy()\n",
    "  return(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ns3HxGmZsyNA"
   },
   "outputs": [],
   "source": [
    "# Data Transformation: Function for min max tranform of the data\n",
    "def minmaxtrans(data):\n",
    "  dataset = np.reshape(data.values, (len(data.values), 1))\n",
    "  sc = MinMaxScaler()\n",
    "  dataset = sc.fit_transform(dataset) \n",
    "  return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNdkBWKXRu1e"
   },
   "outputs": [],
   "source": [
    "# Create LSTM Model : Keras Architecture setup\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(128,activation=\"sigmoid\",input_shape=(1,1)))\n",
    "  model.add(Dropout(0.2))\n",
    "  model.add(Dense(1))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eywVcZc9R8_j"
   },
   "outputs": [],
   "source": [
    "#load the dataset \n",
    "data = pd.read_csv('BTCUSD_hourly_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date for splitting\n",
    "split_date = '25-Jun-2018'\n",
    "\n",
    "# Data preprocessing\n",
    "data_pre= preprocess(data)\n",
    "data_train, data_test = split(data_pre, split_date)\n",
    "trainingset = minmaxtrans(data_train)\n",
    "\n",
    "# Defining the X and y values for the model\n",
    "X_train = trainingset[0:len(trainingset)-1]\n",
    "y_train = trainingset[1:len(trainingset)]\n",
    "X_train = np.reshape(X_train, (len(X_train), 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "colab_type": "code",
    "id": "27sokzpWwIFx",
    "outputId": "cf7771b7-a617-4fdc-9054-2bfd79f3fcb6"
   },
   "outputs": [],
   "source": [
    "# Compile and fit model\n",
    "model = create_model()\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=50, verbose=2)\n",
    "model.summary()\n",
    "\n",
    "# saving the trained model and model weights\n",
    "model.save(\"forecast_model.h5\")\n",
    "model.save_weights(\"forecast_weights.h5\")\n",
    "print(\"Saved model and the weights to the disk\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "kUesaDqgHBys",
    "outputId": "975e0660-c950-45f1-eb49-ad4bbd226f54"
   },
   "outputs": [],
   "source": [
    "#Testing the LSTM model\n",
    "\n",
    "# load the trained model\n",
    "model = load_model('forecast_model.h5')\n",
    "\n",
    "# data transformation of the test dataset\n",
    "testset = np.reshape(data_test.values, (len(data_test.values), 1))\n",
    "sc = MinMaxScaler()\n",
    "testset = sc.fit_transform(testset) \n",
    "X_test = np.reshape(testset, (len(testset), 1, 1))\n",
    "\n",
    "# model prediction of test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = sc.inverse_transform(y_pred)\n",
    "data_test['close_prediction'] = y_pred\n",
    "\n",
    "# model prediction using 20-point average for baseline scenario\n",
    "data_test['close_prediction_ma'] = data_test['close'].rolling(20).mean()\n",
    "\n",
    "# remove the first 20 values of the test dataset for a MSE comparison of LSTM and MA model\n",
    "data_test=data_test[19:]\n",
    "\n",
    "#Model Performance: MSE calculation\n",
    "score_model= mean_squared_error(data_test['close'], data_test['close_prediction'])\n",
    "print(\"MSE for Model using the LSTM model (Forecasting Model): %.2f\" % (score_model))\n",
    "\n",
    "score_model_ma= mean_squared_error(data_test['close'], data_test['close_prediction_ma'])\n",
    "print(\"MSE for Model using the 20-point moving average (Baseline Model):%.2f\" % (score_model_ma))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Part1_217469305_Ankit_Vijai_Misra_Assignemnt1_AI_II.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
